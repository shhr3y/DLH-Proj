{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/shreygupta/Documents/Classes/CS598DLH'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/Users/shreygupta/Documents/Classes/CS598DLH/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from feature_generation import FeatureGeneration\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import csv\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import weka.core.jvm as jvm\n",
    "from weka.core.converters import Loader\n",
    "from weka.filters import Filter\n",
    "from weka.attribute_selection import ASEvaluation, AttributeSelection\n",
    "from weka.classifiers import Classifier, Evaluation\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# jvm.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, x_train, y_train, x_test, y_test, n, k):\n",
    "        self.knn = KNeighborsClassifier(n_neighbors=n)\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.k = k\n",
    "\n",
    "    def feature_selection_SelectKBest(self):\n",
    "        k_best = SelectKBest(chi2, k=self.k)\n",
    "        k_best.fit(self.x_train, self.y_train)\n",
    "        self.x_train = k_best.transform(self.x_train)\n",
    "        self.x_test = k_best.transform(self.x_test)\n",
    "        \n",
    "    def feature_selection_ExtraTreesClassifier(self):\n",
    "        clf = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "        clf.fit(self.x_train, self.y_train)\n",
    "        importances = clf.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        self.x_train = self.x_train[:, indices[:self.k]]\n",
    "        self.x_test = self.x_test[:, indices[:self.k]]\n",
    "    \n",
    "    def feature_selection_InfoGainAttributeEval(self, morbidity):\n",
    "        loader = Loader(classname=\"weka.core.converters.ArffLoader\")\n",
    "        train_data = loader.load_file(f\"./dataset/train/train_{morbidity}_tfidf.arff\")\n",
    "        train_data.class_is_last()\n",
    "\n",
    "        # Initialize attribute selection\n",
    "        eval = ASEvaluation(classname=\"weka.attributeSelection.InfoGainAttributeEval\")\n",
    "        search = AttributeSelection()\n",
    "        search.evaluator = eval\n",
    "        search.select_attributes(train_data)\n",
    "        selected_attributes = search.selected_attributes\n",
    "        filtered_attributes = np.delete(selected_attributes, [-1])\n",
    "        # print(\"Selected attributes:\", type(filtered_attributes), filtered_attributes.shape)\n",
    "\n",
    "        # Apply selected attributes to the training and testing sets\n",
    "        self.x_train = self.x_train[:, filtered_attributes]\n",
    "        self.x_test = self.x_test[:, filtered_attributes]\n",
    "\n",
    "    def train(self):\n",
    "        self.knn.fit(self.x_train, self.y_train)\n",
    "\n",
    "    def test_and_evaluate(self):\n",
    "        y_pred = self.knn.predict(self.x_test)\n",
    "        f1_macro = f1_score(self.y_test, y_pred, average='macro')\n",
    "        f1_micro = f1_score(self.y_test, y_pred, average='micro')\n",
    "        return f1_macro, f1_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "morbidities = ['Asthma', 'CAD', 'CHF', 'Depression', 'Diabetes', 'Gallstones', 'GERD', 'Gout', 'Hypercholesterolemia', 'Hypertension', 'Hypertriglyceridemia', 'OA', 'Obesity', 'OSA', 'PVD', 'Venous_Insufficiency']\n",
    "column_headings = [\"Morbidity Class\", \"KNN1_Macro F1\", \"KNN1_Micro F1\", \"KNN5_Macro F1\", \"KNN5_Micro F1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asthma\n",
      "Asthma\n",
      "For n=1, Macro F1 score: 0.666596314935899 and Micro F1 Score 0.7002574257425742\n",
      "For n=5, Macro F1 score: 0.5658725563187745 and Micro F1 Score 0.6285643564356437\n",
      "CAD\n",
      "CAD\n",
      "For n=1, Macro F1 score: 0.6783371879278528 and Micro F1 Score 0.6984615384615385\n",
      "For n=5, Macro F1 score: 0.675525028273199 and Micro F1 Score 0.6907692307692308\n",
      "CHF\n",
      "For n=1, Macro F1 score: 1 and Micro F1 Score 1\n",
      "For n=5, Macro F1 score: 1 and Micro F1 Score 1\n",
      "Depression\n",
      "Depression\n",
      "For n=1, Macro F1 score: 0.6578570174318714 and Micro F1 Score 0.6891304347826088\n",
      "For n=5, Macro F1 score: 0.5550205629698999 and Micro F1 Score 0.6173913043478261\n",
      "Diabetes\n",
      "Diabetes\n",
      "For n=1, Macro F1 score: 0.610365511084751 and Micro F1 Score 0.6527689873417721\n",
      "For n=5, Macro F1 score: 0.5111652043293369 and Micro F1 Score 0.5870727848101265\n",
      "Gallstones\n",
      "Gallstones\n",
      "For n=1, Macro F1 score: 0.6212062738762162 and Micro F1 Score 0.6639487478159579\n",
      "For n=5, Macro F1 score: 0.501312232317052 and Micro F1 Score 0.5868472141331781\n",
      "GERD\n",
      "GERD\n",
      "For n=1, Macro F1 score: 0.5597173608111085 and Micro F1 Score 0.6237297297297297\n",
      "For n=5, Macro F1 score: 0.42660194687138436 and Micro F1 Score 0.5431891891891892\n",
      "Gout\n",
      "Gout\n",
      "For n=1, Macro F1 score: 0.6060855948044426 and Micro F1 Score 0.6536781179985064\n",
      "For n=5, Macro F1 score: 0.45827115995136297 and Micro F1 Score 0.562957430918596\n",
      "Hypercholesterolemia\n",
      "Hypercholesterolemia\n",
      "For n=1, Macro F1 score: 0.6282805894864987 and Micro F1 Score 0.6356676342525399\n",
      "For n=5, Macro F1 score: 0.6270494499135703 and Micro F1 Score 0.6318577648766329\n",
      "Hypertension\n",
      "Hypertension\n",
      "For n=1, Macro F1 score: 0.5937202197495279 and Micro F1 Score 0.6461149110807114\n",
      "For n=5, Macro F1 score: 0.47290275100050394 and Micro F1 Score 0.5712995896032831\n",
      "Hypertriglyceridemia\n",
      "Hypertriglyceridemia\n",
      "For n=1, Macro F1 score: 0.7053021863776532 and Micro F1 Score 0.7293038493038493\n",
      "For n=5, Macro F1 score: 0.5625857446739192 and Micro F1 Score 0.6255610155610156\n",
      "OA\n",
      "OA\n",
      "For n=1, Macro F1 score: 0.5841841935738579 and Micro F1 Score 0.6392930679478381\n",
      "For n=5, Macro F1 score: 0.48757147970448395 and Micro F1 Score 0.578231525966598\n",
      "Obesity\n",
      "Obesity\n",
      "For n=1, Macro F1 score: 0.5863524143421623 and Micro F1 Score 0.6130824372759858\n",
      "For n=5, Macro F1 score: 0.5350362501912427 and Micro F1 Score 0.5827956989247312\n",
      "OSA\n",
      "OSA\n",
      "For n=1, Macro F1 score: 0.6269239507576302 and Micro F1 Score 0.6688992428654629\n",
      "For n=5, Macro F1 score: 0.501778258529982 and Micro F1 Score 0.5888662395651328\n",
      "PVD\n",
      "PVD\n",
      "For n=1, Macro F1 score: 0.6169987170179926 and Micro F1 Score 0.6620567375886525\n",
      "For n=5, Macro F1 score: 0.48899929686988086 and Micro F1 Score 0.581102722489133\n",
      "Venous_Insufficiency\n",
      "Venous_Insufficiency\n",
      "For n=1, Macro F1 score: 0.671857720093002 and Micro F1 Score 0.705455326460481\n",
      "For n=5, Macro F1 score: 0.5477034682002041 and Micro F1 Score 0.61830970790378\n"
     ]
    }
   ],
   "source": [
    "with open(\"./results/tf-idf/performance_KNN_AllFeatures.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([column_headings[0], column_headings[1], column_headings[2], column_headings[3], column_headings[4]])\n",
    "\n",
    "all_f1_macro1_scores = []\n",
    "all_f1_micro1_scores = []\n",
    "\n",
    "all_f1_macro5_scores = []\n",
    "all_f1_micro5_scores = []\n",
    "\n",
    "for morbidity in morbidities:\n",
    "    print(morbidity)\n",
    "    train_preprocessed_df = pd.read_csv('./dataset/train/train_intuitive_preprocessed.csv')\n",
    "    train_preprocessed_df = train_preprocessed_df[train_preprocessed_df[morbidity].isin([1.0, 0.0])]\n",
    "\n",
    "    X, Y, words = FeatureGeneration(train_preprocessed_df, morbidity).tf_idf()\n",
    "\n",
    "    if len(collections.Counter(list(Y)).keys()) >=2:\n",
    "        print(morbidity)\n",
    "        smote = SMOTE(random_state=42,k_neighbors=2)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X, Y)\n",
    "        X, Y =  X_train_resampled, y_train_resampled\n",
    "    \n",
    "        # add KFold cross validation\n",
    "        skf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "        f1_macro_list1 = []\n",
    "        f1_micro_list1 = []\n",
    "        f1_macro_list5 = []\n",
    "        f1_micro_list5 = []\n",
    "        for train_idx, val_idx in skf.split(X, Y):\n",
    "            X_train_fold, Y_train_fold = X[train_idx], Y[train_idx]\n",
    "            X_val_fold, Y_val_fold = X[val_idx], Y[val_idx]\n",
    "\n",
    "            # Training KNN using TF-IDF Representation\n",
    "            knn1_obj = KNN(X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, 1, 100)\n",
    "            knn1_obj.train()\n",
    "\n",
    "            f1_macro1, f1_micro1 = knn1_obj.test_and_evaluate()\n",
    "\n",
    "            f1_macro_list1.append(f1_macro1)\n",
    "            f1_micro_list1.append(f1_micro1)\n",
    "\n",
    "            knn5_obj = KNN(X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, 5, 100)\n",
    "            knn5_obj.train()\n",
    "\n",
    "            f1_macro5, f1_micro5 = knn5_obj.test_and_evaluate()\n",
    "\n",
    "            f1_macro_list5.append(f1_macro5)\n",
    "            f1_micro_list5.append(f1_micro5)\n",
    "\n",
    "        f1_macro1 = np.mean(f1_macro_list1)\n",
    "        f1_micro1 = np.mean(f1_micro_list1)\n",
    "        f1_macro5 = np.mean(f1_macro_list5)\n",
    "        f1_micro5 = np.mean(f1_micro_list5)\n",
    "    \n",
    "    else:\n",
    "        f1_macro1 = 1\n",
    "        f1_micro1 = 1\n",
    "        f1_macro5 = 1\n",
    "        f1_micro5 = 1\n",
    "        \n",
    "    print(f\"For n=1, Macro F1 score: {f1_macro1} and Micro F1 Score {f1_micro1}\")\n",
    "    print(f\"For n=5, Macro F1 score: {f1_macro5} and Micro F1 Score {f1_micro5}\")\n",
    "\n",
    "    row_heading = morbidity\n",
    "\n",
    "    # data to be written to the CSV file\n",
    "    data = [f1_macro1, f1_micro1, f1_macro5, f1_micro5]\n",
    "    all_f1_macro1_scores.append(f1_macro1)\n",
    "    all_f1_micro1_scores.append(f1_micro1)\n",
    "\n",
    "    all_f1_macro5_scores.append(f1_macro5)\n",
    "    all_f1_micro5_scores.append(f1_micro5)\n",
    "\n",
    "\n",
    "    with open(\"./results/tf-idf/performance_KNN_AllFeatures.csv\", \"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        row = [row_heading]\n",
    "        row.extend(data)\n",
    "        writer.writerow(row)\n",
    "\n",
    "with open(\"./results/tf-idf/performance_KNN_AllFeatures.csv\", \"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    row = [\"Average\"]\n",
    "    row.extend([\n",
    "        sum(all_f1_macro1_scores)/len(all_f1_macro1_scores),  sum(all_f1_micro1_scores)/len(all_f1_micro1_scores),\n",
    "        sum(all_f1_macro5_scores)/len(all_f1_macro5_scores),  sum(all_f1_micro5_scores)/len(all_f1_micro5_scores) \n",
    "                ])\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asthma\n",
      "Asthma\n",
      "For n=1, Macro F1 score: 0.890493280004576 and Micro F1 Score 0.8924851485148514\n",
      "For n=5, Macro F1 score: 0.796041498811422 and Micro F1 Score 0.8047821782178218\n",
      "CAD\n",
      "CAD\n",
      "For n=1, Macro F1 score: 0.7403619083195547 and Micro F1 Score 0.7461538461538462\n",
      "For n=5, Macro F1 score: 0.7127469581507913 and Micro F1 Score 0.7215384615384617\n",
      "CHF\n",
      "For n=1, Macro F1 score: 1 and Micro F1 Score 1\n",
      "For n=5, Macro F1 score: 1 and Micro F1 Score 1\n",
      "Depression\n",
      "Depression\n",
      "For n=1, Macro F1 score: 0.8272582613330766 and Micro F1 Score 0.8315217391304348\n",
      "For n=5, Macro F1 score: 0.7322497195056643 and Micro F1 Score 0.7467391304347826\n",
      "Diabetes\n",
      "Diabetes\n",
      "For n=1, Macro F1 score: 0.7646317042099939 and Micro F1 Score 0.7740981012658229\n",
      "For n=5, Macro F1 score: 0.7023427726053404 and Micro F1 Score 0.7210759493670886\n",
      "Gallstones\n",
      "Gallstones\n",
      "For n=1, Macro F1 score: 0.7991998740756393 and Micro F1 Score 0.8091729761211415\n",
      "For n=5, Macro F1 score: 0.7116011539184095 and Micro F1 Score 0.7340904678703164\n",
      "GERD\n",
      "GERD\n",
      "For n=1, Macro F1 score: 0.7548780723891187 and Micro F1 Score 0.7674954954954956\n",
      "For n=5, Macro F1 score: 0.6677697699284904 and Micro F1 Score 0.6882522522522523\n",
      "Gout\n",
      "Gout\n",
      "For n=1, Macro F1 score: 0.8492115552720649 and Micro F1 Score 0.8533980582524272\n",
      "For n=5, Macro F1 score: 0.7728197501854875 and Micro F1 Score 0.7838778939507094\n",
      "Hypercholesterolemia\n",
      "Hypercholesterolemia\n",
      "For n=1, Macro F1 score: 0.5956835141521846 and Micro F1 Score 0.606676342525399\n",
      "For n=5, Macro F1 score: 0.6350319286747889 and Micro F1 Score 0.6469158200290275\n",
      "Hypertension\n",
      "Hypertension\n",
      "For n=1, Macro F1 score: 0.779087587035792 and Micro F1 Score 0.7896853625171\n",
      "For n=5, Macro F1 score: 0.681056890209455 and Micro F1 Score 0.7056908344733243\n",
      "Hypertriglyceridemia\n",
      "Hypertriglyceridemia\n",
      "For n=1, Macro F1 score: 0.922959100146796 and Micro F1 Score 0.9241850941850942\n",
      "For n=5, Macro F1 score: 0.8359096369461451 and Micro F1 Score 0.842031122031122\n",
      "OA\n",
      "OA\n",
      "For n=1, Macro F1 score: 0.8360722571344823 and Micro F1 Score 0.8415351178220087\n",
      "For n=5, Macro F1 score: 0.741789151488869 and Micro F1 Score 0.7558911004346831\n",
      "Obesity\n",
      "Obesity\n",
      "For n=1, Macro F1 score: 0.7024235129307191 and Micro F1 Score 0.7068868407578085\n",
      "For n=5, Macro F1 score: 0.639081994312382 and Micro F1 Score 0.6431387608806964\n",
      "OSA\n",
      "OSA\n",
      "For n=1, Macro F1 score: 0.888604825903973 and Micro F1 Score 0.891283245971656\n",
      "For n=5, Macro F1 score: 0.7929787733661212 and Micro F1 Score 0.8023102310231023\n",
      "PVD\n",
      "PVD\n",
      "For n=1, Macro F1 score: 0.853919352603483 and Micro F1 Score 0.8592884923358499\n",
      "For n=5, Macro F1 score: 0.7596824654204893 and Micro F1 Score 0.7750972317547473\n",
      "Venous_Insufficiency\n",
      "Venous_Insufficiency\n",
      "For n=1, Macro F1 score: 0.9084580048317923 and Micro F1 Score 0.9108032646048111\n",
      "For n=5, Macro F1 score: 0.8276510442805934 and Micro F1 Score 0.8361039518900343\n"
     ]
    }
   ],
   "source": [
    "with open(\"./results/tf-idf/performance_KNN_SelectKBest.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([column_headings[0], column_headings[1], column_headings[2], column_headings[3], column_headings[4]])\n",
    "\n",
    "all_f1_macro1_scores = []\n",
    "all_f1_micro1_scores = []\n",
    "\n",
    "all_f1_macro5_scores = []\n",
    "all_f1_micro5_scores = []\n",
    "\n",
    "for morbidity in morbidities:\n",
    "    print(morbidity)\n",
    "    train_preprocessed_df = pd.read_csv('./dataset/train/train_intuitive_preprocessed.csv')\n",
    "    train_preprocessed_df = train_preprocessed_df[train_preprocessed_df[morbidity].isin([1.0, 0.0])]\n",
    "\n",
    "    X, Y, words = FeatureGeneration(train_preprocessed_df, morbidity).tf_idf()\n",
    "\n",
    "    if len(collections.Counter(list(Y)).keys()) >=2:\n",
    "        print(morbidity)\n",
    "        smote = SMOTE(random_state=42,k_neighbors=2)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X, Y)\n",
    "        X, Y =  X_train_resampled, y_train_resampled\n",
    "\n",
    "        # add KFold cross validation\n",
    "        skf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "        f1_macro_list1 = []\n",
    "        f1_micro_list1 = []\n",
    "        f1_macro_list5 = []\n",
    "        f1_micro_list5 = []\n",
    "        for train_idx, val_idx in skf.split(X, Y):\n",
    "            X_train_fold, Y_train_fold = X[train_idx], Y[train_idx]\n",
    "            X_val_fold, Y_val_fold = X[val_idx], Y[val_idx]\n",
    "\n",
    "            # Training KNN using TF-IDF Representation\n",
    "            knn1_obj = KNN(X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, 1, 100)\n",
    "            knn1_obj.feature_selection_SelectKBest()\n",
    "            knn1_obj.train()\n",
    "\n",
    "            f1_macro1, f1_micro1 = knn1_obj.test_and_evaluate()\n",
    "\n",
    "            f1_macro_list1.append(f1_macro1)\n",
    "            f1_micro_list1.append(f1_micro1)\n",
    "\n",
    "            knn5_obj = KNN(X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, 5, 100)\n",
    "            knn5_obj.feature_selection_SelectKBest()\n",
    "            knn5_obj.train()\n",
    "\n",
    "            f1_macro5, f1_micro5 = knn5_obj.test_and_evaluate()\n",
    "\n",
    "            f1_macro_list5.append(f1_macro5)\n",
    "            f1_micro_list5.append(f1_micro5)\n",
    "\n",
    "        f1_macro1 = np.mean(f1_macro_list1)\n",
    "        f1_micro1 = np.mean(f1_micro_list1)\n",
    "        f1_macro5 = np.mean(f1_macro_list5)\n",
    "        f1_micro5 = np.mean(f1_micro_list5)\n",
    "    else:\n",
    "        f1_macro1 = 1\n",
    "        f1_micro1 = 1\n",
    "        f1_macro5 = 1\n",
    "        f1_micro5 = 1\n",
    "    \n",
    "    print(f\"For n=1, Macro F1 score: {f1_macro1} and Micro F1 Score {f1_micro1}\")\n",
    "    print(f\"For n=5, Macro F1 score: {f1_macro5} and Micro F1 Score {f1_micro5}\")\n",
    "\n",
    "    row_heading = morbidity\n",
    "\n",
    "    # data to be written to the CSV file\n",
    "    data = [f1_macro1, f1_micro1, f1_macro5, f1_micro5]\n",
    "    all_f1_macro1_scores.append(f1_macro1)\n",
    "    all_f1_micro1_scores.append(f1_micro1)\n",
    "\n",
    "    all_f1_macro5_scores.append(f1_macro5)\n",
    "    all_f1_micro5_scores.append(f1_micro5)\n",
    "\n",
    "\n",
    "    with open(\"./results/tf-idf/performance_KNN_SelectKBest.csv\", \"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        row = [row_heading]\n",
    "        row.extend(data)\n",
    "        writer.writerow(row)\n",
    "\n",
    "with open(\"./results/tf-idf/performance_KNN_SelectKBest.csv\", \"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    row = [\"Average\"]\n",
    "    row.extend([\n",
    "        sum(all_f1_macro1_scores)/len(all_f1_macro1_scores),  sum(all_f1_micro1_scores)/len(all_f1_micro1_scores),\n",
    "        sum(all_f1_macro5_scores)/len(all_f1_macro5_scores),  sum(all_f1_micro5_scores)/len(all_f1_micro5_scores) \n",
    "                ])\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asthma\n",
      "Asthma\n",
      "For n=1, Macro F1 score: 0.8988019940795289 and Micro F1 Score 0.9004455445544555\n",
      "For n=5, Macro F1 score: 0.8412949340349766 and Micro F1 Score 0.8456831683168315\n",
      "CAD\n",
      "CAD\n",
      "For n=1, Macro F1 score: 0.7523888550328193 and Micro F1 Score 0.76\n",
      "For n=5, Macro F1 score: 0.7251629371948626 and Micro F1 Score 0.7353846153846153\n",
      "CHF\n",
      "For n=1, Macro F1 score: 1 and Micro F1 Score 1\n",
      "For n=5, Macro F1 score: 1 and Micro F1 Score 1\n",
      "Depression\n",
      "Depression\n",
      "For n=1, Macro F1 score: 0.8211046606291376 and Micro F1 Score 0.8271739130434783\n",
      "For n=5, Macro F1 score: 0.730823992771722 and Micro F1 Score 0.7445652173913044\n",
      "Diabetes\n",
      "Diabetes\n",
      "For n=1, Macro F1 score: 0.7841690085515248 and Micro F1 Score 0.7916930379746836\n",
      "For n=5, Macro F1 score: 0.7283298308598628 and Micro F1 Score 0.7437816455696202\n",
      "Gallstones\n",
      "Gallstones\n",
      "For n=1, Macro F1 score: 0.76207675286301 and Micro F1 Score 0.7776451174529218\n",
      "For n=5, Macro F1 score: 0.6510881906267352 and Micro F1 Score 0.6876625897883906\n",
      "GERD\n",
      "GERD\n",
      "For n=1, Macro F1 score: 0.7473975570431675 and Micro F1 Score 0.7621261261261261\n",
      "For n=5, Macro F1 score: 0.6074224013544715 and Micro F1 Score 0.6438918918918919\n",
      "Gout\n",
      "Gout\n",
      "For n=1, Macro F1 score: 0.7907581062772946 and Micro F1 Score 0.7994305451829724\n",
      "For n=5, Macro F1 score: 0.7011553838322725 and Micro F1 Score 0.7251120238984317\n",
      "Hypercholesterolemia\n",
      "Hypercholesterolemia\n",
      "For n=1, Macro F1 score: 0.6671554643678554 and Micro F1 Score 0.6738026124818578\n",
      "For n=5, Macro F1 score: 0.6793051739660783 and Micro F1 Score 0.6890420899854862\n",
      "Hypertension\n",
      "Hypertension\n",
      "For n=1, Macro F1 score: 0.8078215999772599 and Micro F1 Score 0.8154172366621066\n",
      "For n=5, Macro F1 score: 0.7220310723719615 and Micro F1 Score 0.7383584131326949\n",
      "Hypertriglyceridemia\n",
      "Hypertriglyceridemia\n",
      "For n=1, Macro F1 score: 0.9186015962726998 and Micro F1 Score 0.9197051597051598\n",
      "For n=5, Macro F1 score: 0.840221129237625 and Micro F1 Score 0.8457002457002456\n",
      "OA\n",
      "OA\n",
      "For n=1, Macro F1 score: 0.7849668909673678 and Micro F1 Score 0.7954930221917181\n",
      "For n=5, Macro F1 score: 0.7010991462673959 and Micro F1 Score 0.7227064744909633\n",
      "Obesity\n",
      "Obesity\n",
      "For n=1, Macro F1 score: 0.7000886263936211 and Micro F1 Score 0.7052739375320021\n",
      "For n=5, Macro F1 score: 0.6529558334534792 and Micro F1 Score 0.6560931899641578\n",
      "OSA\n",
      "OSA\n",
      "For n=1, Macro F1 score: 0.8797656804209387 and Micro F1 Score 0.8824208891477383\n",
      "For n=5, Macro F1 score: 0.8175019634059708 and Micro F1 Score 0.8241506503591536\n",
      "PVD\n",
      "PVD\n",
      "For n=1, Macro F1 score: 0.8496422577431041 and Micro F1 Score 0.8550674902768247\n",
      "For n=5, Macro F1 score: 0.7579239132864494 and Micro F1 Score 0.7718714253031342\n",
      "Venous_Insufficiency\n",
      "Venous_Insufficiency\n",
      "For n=1, Macro F1 score: 0.8951118647304452 and Micro F1 Score 0.8983569587628866\n",
      "For n=5, Macro F1 score: 0.8108125935400473 and Micro F1 Score 0.8205648625429554\n"
     ]
    }
   ],
   "source": [
    "with open(\"./results/tf-idf/performance_KNN_ExtraTreesClassifier.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([column_headings[0], column_headings[1], column_headings[2], column_headings[3], column_headings[4]])\n",
    "\n",
    "all_f1_macro1_scores = []\n",
    "all_f1_micro1_scores = []\n",
    "\n",
    "all_f1_macro5_scores = []\n",
    "all_f1_micro5_scores = []\n",
    "\n",
    "for morbidity in morbidities:\n",
    "    print(morbidity)\n",
    "    train_preprocessed_df = pd.read_csv('./dataset/train/train_intuitive_preprocessed.csv')\n",
    "    train_preprocessed_df = train_preprocessed_df[train_preprocessed_df[morbidity].isin([1.0, 0.0])]\n",
    "\n",
    "    X, Y, words = FeatureGeneration(train_preprocessed_df, morbidity).tf_idf()\n",
    "\n",
    "    if len(collections.Counter(list(Y)).keys()) >=2:\n",
    "        print(morbidity)\n",
    "        smote = SMOTE(random_state=42,k_neighbors=2)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X, Y)\n",
    "        X, Y =  X_train_resampled, y_train_resampled\n",
    "\n",
    "        # add KFold cross validation\n",
    "        skf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "        f1_macro_list1 = []\n",
    "        f1_micro_list1 = []\n",
    "        f1_macro_list5 = []\n",
    "        f1_micro_list5 = []\n",
    "        for train_idx, val_idx in skf.split(X, Y):\n",
    "            X_train_fold, Y_train_fold = X[train_idx], Y[train_idx]\n",
    "            X_val_fold, Y_val_fold = X[val_idx], Y[val_idx]\n",
    "\n",
    "            # Training KNN using TF-IDF Representation\n",
    "            knn1_obj = KNN(X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, 1, 100)\n",
    "            knn1_obj.feature_selection_ExtraTreesClassifier()\n",
    "            knn1_obj.train()\n",
    "\n",
    "            f1_macro1, f1_micro1 = knn1_obj.test_and_evaluate()\n",
    "\n",
    "            f1_macro_list1.append(f1_macro1)\n",
    "            f1_micro_list1.append(f1_micro1)\n",
    "\n",
    "            knn5_obj = KNN(X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, 5, 100)\n",
    "            knn5_obj.feature_selection_ExtraTreesClassifier()\n",
    "            knn5_obj.train()\n",
    "\n",
    "            f1_macro5, f1_micro5 = knn5_obj.test_and_evaluate()\n",
    "\n",
    "            f1_macro_list5.append(f1_macro5)\n",
    "            f1_micro_list5.append(f1_micro5)\n",
    "\n",
    "        f1_macro1 = np.mean(f1_macro_list1)\n",
    "        f1_micro1 = np.mean(f1_micro_list1)\n",
    "        f1_macro5 = np.mean(f1_macro_list5)\n",
    "        f1_micro5 = np.mean(f1_micro_list5)\n",
    "    else:\n",
    "        f1_macro1 = 1\n",
    "        f1_micro1 = 1\n",
    "        f1_macro5 = 1\n",
    "        f1_micro5 = 1\n",
    "        \n",
    "    print(f\"For n=1, Macro F1 score: {f1_macro1} and Micro F1 Score {f1_micro1}\")\n",
    "    print(f\"For n=5, Macro F1 score: {f1_macro5} and Micro F1 Score {f1_micro5}\")\n",
    "\n",
    "    row_heading = morbidity\n",
    "\n",
    "    # data to be written to the CSV file\n",
    "    data = [f1_macro1, f1_micro1, f1_macro5, f1_micro5]\n",
    "    all_f1_macro1_scores.append(f1_macro1)\n",
    "    all_f1_micro1_scores.append(f1_micro1)\n",
    "\n",
    "    all_f1_macro5_scores.append(f1_macro5)\n",
    "    all_f1_micro5_scores.append(f1_micro5)\n",
    "\n",
    "\n",
    "    with open(\"./results/tf-idf/performance_KNN_ExtraTreesClassifier.csv\", \"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        row = [row_heading]\n",
    "        row.extend(data)\n",
    "        writer.writerow(row)\n",
    "\n",
    "with open(\"./results/tf-idf/performance_KNN_ExtraTreesClassifier.csv\", \"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    row = [\"Average\"]\n",
    "    row.extend([\n",
    "        sum(all_f1_macro1_scores)/len(all_f1_macro1_scores),  sum(all_f1_micro1_scores)/len(all_f1_micro1_scores),\n",
    "        sum(all_f1_macro5_scores)/len(all_f1_macro5_scores),  sum(all_f1_micro5_scores)/len(all_f1_micro5_scores) \n",
    "                ])\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asthma\n",
      "Asthma\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m# Training KNN using TF-IDF Representation\u001b[39;00m\n\u001b[1;32m     40\u001b[0m knn1_obj \u001b[39m=\u001b[39m KNN(X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, \u001b[39m1\u001b[39m, \u001b[39m100\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m knn1_obj\u001b[39m.\u001b[39;49mfeature_selection_InfoGainAttributeEval(morbidity)\n\u001b[1;32m     42\u001b[0m knn1_obj\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     44\u001b[0m f1_macro1, f1_micro1 \u001b[39m=\u001b[39m knn1_obj\u001b[39m.\u001b[39mtest_and_evaluate()\n",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m, in \u001b[0;36mKNN.feature_selection_InfoGainAttributeEval\u001b[0;34m(self, morbidity)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeature_selection_InfoGainAttributeEval\u001b[39m(\u001b[39mself\u001b[39m, morbidity):\n\u001b[0;32m---> 25\u001b[0m     loader \u001b[39m=\u001b[39m Loader(classname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mweka.core.converters.ArffLoader\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     26\u001b[0m     train_data \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mload_file(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./dataset/train/train_\u001b[39m\u001b[39m{\u001b[39;00mmorbidity\u001b[39m}\u001b[39;00m\u001b[39m_tfidf.arff\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m     train_data\u001b[39m.\u001b[39mclass_is_last()\n",
      "File \u001b[0;32m~/Documents/Classes/CS598DLH/.conda/lib/python3.10/site-packages/weka/core/converters.py:42\u001b[0m, in \u001b[0;36mLoader.__init__\u001b[0;34m(self, classname, jobject, options)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39mInitializes the specified loader either using the classname or the JB_Object.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m:type options: list\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m jobject \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     jobject \u001b[39m=\u001b[39m Loader\u001b[39m.\u001b[39;49mnew_instance(classname)\n\u001b[1;32m     43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menforce_type(jobject, \u001b[39m\"\u001b[39m\u001b[39mweka.core.converters.Loader\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[39msuper\u001b[39m(Loader, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(jobject\u001b[39m=\u001b[39mjobject, options\u001b[39m=\u001b[39moptions)\n",
      "File \u001b[0;32m~/Documents/Classes/CS598DLH/.conda/lib/python3.10/site-packages/weka/core/classes.py:614\u001b[0m, in \u001b[0;36mJavaObject.new_instance\u001b[0;34m(cls, classname, options)\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[39mif\u001b[39;00m options \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    610\u001b[0m         options \u001b[39m=\u001b[39m []\n\u001b[1;32m    611\u001b[0m     \u001b[39mreturn\u001b[39;00m javabridge\u001b[39m.\u001b[39mstatic_call(\n\u001b[1;32m    612\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLweka/core/Utils;\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mforName\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    613\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(Ljava/lang/Class;Ljava/lang/String;[Ljava/lang/String;)Ljava/lang/Object;\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m--> 614\u001b[0m         javabridge\u001b[39m.\u001b[39;49mclass_for_name(\u001b[39m\"\u001b[39;49m\u001b[39mjava.lang.Object\u001b[39;49m\u001b[39m\"\u001b[39;49m), classname, options)\n\u001b[1;32m    615\u001b[0m \u001b[39mexcept\u001b[39;00m JavaException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    616\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFailed to instantiate \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m classname \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/Documents/Classes/CS598DLH/.conda/lib/python3.10/site-packages/javabridge/jutil.py:1743\u001b[0m, in \u001b[0;36mclass_for_name\u001b[0;34m(classname, ldr)\u001b[0m\n\u001b[1;32m   1737\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''Return a ``java.lang.Class`` for the given name.\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[1;32m   1739\u001b[0m \u001b[39m:param classname: the class name in dotted form, e.g. \"java.lang.String\"\u001b[39;00m\n\u001b[1;32m   1740\u001b[0m \n\u001b[1;32m   1741\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m ldr \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 1743\u001b[0m     ldr \u001b[39m=\u001b[39m static_call(\u001b[39m'\u001b[39;49m\u001b[39mjava/lang/ClassLoader\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mgetSystemClassLoader\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m   1744\u001b[0m                       \u001b[39m'\u001b[39;49m\u001b[39m()Ljava/lang/ClassLoader;\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m   1745\u001b[0m \u001b[39mreturn\u001b[39;00m static_call(\u001b[39m'\u001b[39m\u001b[39mjava/lang/Class\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mforName\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m   1746\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m(Ljava/lang/String;ZLjava/lang/ClassLoader;)\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1747\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mLjava/lang/Class;\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m   1748\u001b[0m                    classname, \u001b[39mTrue\u001b[39;00m, ldr)\n",
      "File \u001b[0;32m~/Documents/Classes/CS598DLH/.conda/lib/python3.10/site-packages/javabridge/jutil.py:939\u001b[0m, in \u001b[0;36mstatic_call\u001b[0;34m(class_name, method_name, sig, *args)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''Call a static method on a class\u001b[39;00m\n\u001b[1;32m    929\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[1;32m    930\u001b[0m \u001b[39m:param class_name: name of the class, using slashes\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    936\u001b[0m \n\u001b[1;32m    937\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    938\u001b[0m env \u001b[39m=\u001b[39m get_env()\n\u001b[0;32m--> 939\u001b[0m fn \u001b[39m=\u001b[39m make_static_call(class_name, method_name, sig)\n\u001b[1;32m    940\u001b[0m args_sig \u001b[39m=\u001b[39m split_sig(sig[\u001b[39m1\u001b[39m:sig\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m)])\n\u001b[1;32m    941\u001b[0m ret_sig \u001b[39m=\u001b[39m sig[sig\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:]\n",
      "File \u001b[0;32m~/Documents/Classes/CS598DLH/.conda/lib/python3.10/site-packages/javabridge/jutil.py:910\u001b[0m, in \u001b[0;36mmake_static_call\u001b[0;34m(class_name, method_name, sig)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''Create a function that performs a call of a static method\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39mmake_static_call produces a function that is faster than static_call\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    907\u001b[0m \n\u001b[1;32m    908\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    909\u001b[0m env \u001b[39m=\u001b[39m get_env()\n\u001b[0;32m--> 910\u001b[0m klass \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mfind_class(class_name)\n\u001b[1;32m    911\u001b[0m \u001b[39mif\u001b[39;00m klass \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    912\u001b[0m     jexception \u001b[39m=\u001b[39m get_env()\u001b[39m.\u001b[39mexception_occurred()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_class'"
     ]
    }
   ],
   "source": [
    "with open(\"./results/tf-idf/performance_KNN_InfoGain.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([column_headings[0], column_headings[1], column_headings[2], column_headings[3], column_headings[4]])\n",
    "\n",
    "all_f1_macro1_scores = []\n",
    "all_f1_micro1_scores = []\n",
    "\n",
    "all_f1_macro5_scores = []\n",
    "all_f1_micro5_scores = []\n",
    "\n",
    "for morbidity in morbidities:\n",
    "    print(morbidity)\n",
    "    train_preprocessed_df = pd.read_csv('./dataset/train/train_intuitive_preprocessed.csv')\n",
    "    train_preprocessed_df = train_preprocessed_df[train_preprocessed_df[morbidity].isin([1.0, 0.0])]\n",
    "\n",
    "    X, Y, words = FeatureGeneration(train_preprocessed_df, morbidity).tf_idf()\n",
    "\n",
    "    \n",
    "    # add KFold cross validation\n",
    "    skf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    if len(collections.Counter(list(Y)).keys()) < 2:\n",
    "        f1_macro1 = 1\n",
    "        f1_micro1 = 1\n",
    "        f1_macro5 = 1\n",
    "        f1_micro5 = 1\n",
    "    else:\n",
    "        print(morbidity)\n",
    "        smote = SMOTE(random_state=42,k_neighbors=2)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X, Y)\n",
    "        X, Y =  X_train_resampled, y_train_resampled\n",
    "        f1_macro_list1 = []\n",
    "        f1_micro_list1 = []\n",
    "        f1_macro_list5 = []\n",
    "        f1_micro_list5 = []\n",
    "        for train_idx, val_idx in skf.split(X, Y):\n",
    "            X_train_fold, Y_train_fold = X[train_idx], Y[train_idx]\n",
    "            X_val_fold, Y_val_fold = X[val_idx], Y[val_idx]\n",
    "\n",
    "            # Training KNN using TF-IDF Representation\n",
    "            knn1_obj = KNN(X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, 1, 100)\n",
    "            knn1_obj.feature_selection_InfoGainAttributeEval(morbidity)\n",
    "            knn1_obj.train()\n",
    "\n",
    "            f1_macro1, f1_micro1 = knn1_obj.test_and_evaluate()\n",
    "\n",
    "            f1_macro_list1.append(f1_macro1)\n",
    "            f1_micro_list1.append(f1_micro1)\n",
    "\n",
    "            knn5_obj = KNN(X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, 5, 100)\n",
    "            knn5_obj.feature_selection_InfoGainAttributeEval(morbidity)\n",
    "            knn5_obj.train()\n",
    "\n",
    "            f1_macro5, f1_micro5 = knn5_obj.test_and_evaluate()\n",
    "\n",
    "            f1_macro_list5.append(f1_macro5)\n",
    "            f1_micro_list5.append(f1_micro5)\n",
    "\n",
    "        f1_macro1 = np.mean(f1_macro_list1)\n",
    "        f1_micro1 = np.mean(f1_micro_list1)\n",
    "        f1_macro5 = np.mean(f1_macro_list5)\n",
    "        f1_micro5 = np.mean(f1_micro_list5)\n",
    "\n",
    "    print(f\"For n=1, Macro F1 score: {f1_macro1} and Micro F1 Score {f1_micro1}\")\n",
    "    print(f\"For n=5, Macro F1 score: {f1_macro5} and Micro F1 Score {f1_micro5}\")\n",
    "\n",
    "    row_heading = morbidity\n",
    "\n",
    "    # data to be written to the CSV file\n",
    "    data = [f1_macro1, f1_micro1, f1_macro5, f1_micro5]\n",
    "    all_f1_macro1_scores.append(f1_macro1)\n",
    "    all_f1_micro1_scores.append(f1_micro1)\n",
    "\n",
    "    all_f1_macro5_scores.append(f1_macro5)\n",
    "    all_f1_micro5_scores.append(f1_micro5)\n",
    "\n",
    "\n",
    "    with open(\"./results/tf-idf/performance_KNN_InfoGain.csv\", \"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        row = [row_heading]\n",
    "        row.extend(data)\n",
    "        writer.writerow(row)\n",
    "\n",
    "with open(\"./results/tf-idf/performance_KNN_InfoGain.csv\", \"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    row = [\"Average\"]\n",
    "    row.extend([\n",
    "        sum(all_f1_macro1_scores)/len(all_f1_macro1_scores),  sum(all_f1_micro1_scores)/len(all_f1_micro1_scores),\n",
    "        sum(all_f1_macro5_scores)/len(all_f1_macro5_scores),  sum(all_f1_micro5_scores)/len(all_f1_micro5_scores) \n",
    "                ])\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
