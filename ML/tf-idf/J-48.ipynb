{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/Users/shreygupta/Documents/Classes/CS598DLH/')\n",
    "os.getcwd()\n",
    "\n",
    "import weka.core.jvm as jvm\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from weka.classifiers import Classifier\n",
    "from weka.core.converters import Loader\n",
    "from weka.core.converters import Loader\n",
    "from weka.classifiers import Evaluation\n",
    "from weka.core.classes import Random\n",
    "\n",
    "from feature_generation import FeatureGeneration\n",
    "\n",
    "\n",
    "jvm.start()\n",
    "loader = Loader(classname=\"weka.core.converters.ArffLoader\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class J48:\n",
    "    def __init__(self, train_data):\n",
    "        self.j48 = Classifier(classname=\"weka.classifiers.trees.J48\")\n",
    "        self.j48.build_classifier(train_data)\n",
    "        self.evaluator = Evaluation(train_data)\n",
    "        # print(self.x_train.shape, self.y_train.shape, self.x_test.shape, self.y_test.shape)\n",
    "    \n",
    "    def test_and_evaluate(self, train_data):\n",
    "        self.evaluator.crossvalidate_model(self.j48, train_data, 10, Random(1))\n",
    "        f1_macro = self.evaluator.weighted_f_measure\n",
    "        f1_micro = self.evaluator.f_measure(1)\n",
    "        # print(f\"Macro F1 score: {f1_macro} and Micro F1 Score {f1_micro}\")\n",
    "        return f1_macro, f1_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morbidities = ['Asthma', 'CAD', 'CHF', 'Depression', 'Diabetes', 'Gallstones', 'GERD', 'Gout', 'Hypercholesterolemia', 'Hypertension', 'Hypertriglyceridemia', 'OA', 'Obesity', 'OSA', 'PVD', 'Venous_Insufficiency']\n",
    "\n",
    "column_headings = [\"Morbidity Class\", \"DT_Macro F1\", \"DT_Micro F1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_f1_macro_scores = []\n",
    "all_f1_micro_scores = []\n",
    "\n",
    "with open(\"./results/tf-idf/performance_J48.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(column_headings)\n",
    "\n",
    "for morbidity in morbidities:\n",
    "    print(morbidity)\n",
    "    f1_macro_list = []\n",
    "    f1_micro_list = []\n",
    "    train_data = loader.load_file(f\"./dataset/train/train_{morbidity}_tfidf.arff\")\n",
    "    train_data.class_is_last()\n",
    "    try:\n",
    "        j48_obj = J48(train_data)\n",
    "        f1_macro, f1_micro = j48_obj.test_and_evaluate(train_data)\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "        f1_macro = 1\n",
    "        f1_micro = 1\n",
    "    print(f\"Macro F1 score: {f1_macro} and Micro F1 Score {f1_micro}\")\n",
    "\n",
    "    row_heading = morbidity\n",
    "\n",
    "    # data to be written to the CSV file\n",
    "    data = [f1_macro, f1_micro]\n",
    "    all_f1_macro_scores.append(f1_macro)\n",
    "    all_f1_micro_scores.append(f1_micro)\n",
    "\n",
    "    with open(\"./results/tf-idf/performance_J48.csv\", \"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        row = [row_heading]\n",
    "        row.extend(data)\n",
    "        writer.writerow(row)\n",
    "\n",
    "\n",
    "with open(\"./results/tf-idf/performance_J48.csv\", \"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    row = [\"Average\"]\n",
    "    row.extend([sum(all_f1_macro_scores)/len(all_f1_macro_scores),  sum(all_f1_micro_scores)/len(all_f1_micro_scores) ])\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_f1_macro_scores = []\n",
    "all_f1_micro_scores = []\n",
    "\n",
    "with open(\"./results/tf-idf/performance_J48_SelectKBest.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(column_headings)\n",
    "\n",
    "for morbidity in morbidities:\n",
    "    print(morbidity)\n",
    "    f1_macro_list = []\n",
    "    f1_micro_list = []\n",
    "    train_data = loader.load_file(f\"./dataset/train/train_{morbidity}_SelectKBest_tfidf.arff\")\n",
    "    train_data.class_is_last()\n",
    "    try:\n",
    "        j48_obj = J48(train_data)\n",
    "        f1_macro, f1_micro = j48_obj.test_and_evaluate(train_data)\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "        f1_macro = 1\n",
    "        f1_micro = 1\n",
    "    print(f\"Macro F1 score: {f1_macro} and Micro F1 Score {f1_micro}\")\n",
    "\n",
    "    row_heading = morbidity\n",
    "\n",
    "    # data to be written to the CSV file\n",
    "    data = [f1_macro, f1_micro]\n",
    "    all_f1_macro_scores.append(f1_macro)\n",
    "    all_f1_micro_scores.append(f1_micro)\n",
    "\n",
    "    with open(\"./results/tf-idf/performance_J48_SelectKBest.csv\", \"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        row = [row_heading]\n",
    "        row.extend(data)\n",
    "        writer.writerow(row)\n",
    "\n",
    "\n",
    "with open(\"./results/tf-idf/performance_J48_SelectKBest.csv\", \"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    row = [\"Average\"]\n",
    "    row.extend([sum(all_f1_macro_scores)/len(all_f1_macro_scores),  sum(all_f1_micro_scores)/len(all_f1_micro_scores) ])\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_f1_macro_scores = []\n",
    "all_f1_micro_scores = []\n",
    "\n",
    "with open(\"./results/tf-idf/performance_J48_ExtraTreesClassifier.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(column_headings)\n",
    "\n",
    "for morbidity in morbidities:\n",
    "    print(morbidity)\n",
    "    f1_macro_list = []\n",
    "    f1_micro_list = []\n",
    "    train_data = loader.load_file(f\"./dataset/train/train_{morbidity}_ExtraTreesClassifier_tfidf.arff\")\n",
    "    train_data.class_is_last()\n",
    "    try:\n",
    "        j48_obj = J48(train_data)\n",
    "        f1_macro, f1_micro = j48_obj.test_and_evaluate(train_data)\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "        f1_macro = 1\n",
    "        f1_micro = 1\n",
    "    print(f\"Macro F1 score: {f1_macro} and Micro F1 Score {f1_micro}\")\n",
    "\n",
    "    row_heading = morbidity\n",
    "\n",
    "    # data to be written to the CSV file\n",
    "    data = [f1_macro, f1_micro]\n",
    "    all_f1_macro_scores.append(f1_macro)\n",
    "    all_f1_micro_scores.append(f1_micro)\n",
    "\n",
    "    with open(\"./results/tf-idf/performance_J48_ExtraTreesClassifier.csv\", \"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        row = [row_heading]\n",
    "        row.extend(data)\n",
    "        writer.writerow(row)\n",
    "\n",
    "\n",
    "with open(\"./results/tf-idf/performance_J48_ExtraTreesClassifier.csv\", \"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    row = [\"Average\"]\n",
    "    row.extend([sum(all_f1_macro_scores)/len(all_f1_macro_scores),  sum(all_f1_micro_scores)/len(all_f1_micro_scores) ])\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_f1_macro_scores = []\n",
    "all_f1_micro_scores = []\n",
    "\n",
    "with open(\"./results/tf-idf/performance_J48_InfoGain.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(column_headings)\n",
    "\n",
    "for morbidity in morbidities:\n",
    "    print(morbidity)\n",
    "    f1_macro_list = []\n",
    "    f1_micro_list = []\n",
    "    train_data = loader.load_file(f\"./dataset/train/train_{morbidity}_InfoGainAttributeEval_tfidf.arff\")\n",
    "    train_data.class_is_last()\n",
    "    try:\n",
    "        j48_obj = J48(train_data)\n",
    "        f1_macro, f1_micro = j48_obj.test_and_evaluate(train_data)\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "        f1_macro = 1\n",
    "        f1_micro = 1\n",
    "    print(f\"Macro F1 score: {f1_macro} and Micro F1 Score {f1_micro}\")\n",
    "\n",
    "    row_heading = morbidity\n",
    "\n",
    "    # data to be written to the CSV file\n",
    "    data = [f1_macro, f1_micro]\n",
    "    all_f1_macro_scores.append(f1_macro)\n",
    "    all_f1_micro_scores.append(f1_micro)\n",
    "\n",
    "    with open(\"./results/tf-idf/performance_J48_InfoGain.csv\", \"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        row = [row_heading]\n",
    "        row.extend(data)\n",
    "        writer.writerow(row)\n",
    "\n",
    "\n",
    "with open(\"./results/tf-idf/performance_J48_InfoGain.csv\", \"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    row = [\"Average\"]\n",
    "    row.extend([sum(all_f1_macro_scores)/len(all_f1_macro_scores),  sum(all_f1_micro_scores)/len(all_f1_micro_scores) ])\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jvm.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
